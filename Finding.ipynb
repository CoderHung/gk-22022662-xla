{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def multi_scale_template_matching(image, template, mask=None, method=cv2.TM_CCOEFF_NORMED, \n",
    "                                scale_range=(0.5, 1.5), steps=10):\n",
    "    best_scale, best_score, best_loc = None, -1, None\n",
    "    template_h, template_w = template.shape[:2]\n",
    "    \n",
    "    for scale in np.linspace(scale_range[0], scale_range[1], steps):\n",
    "        # Resize the image\n",
    "        resized = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Skip if template is larger than resized image\n",
    "        if resized.shape[0] < template_h or resized.shape[1] < template_w:\n",
    "            continue\n",
    "            \n",
    "        # Match template\n",
    "        if mask is not None:\n",
    "            result = cv2.matchTemplate(resized, template, method, mask=mask)\n",
    "        else:\n",
    "            result = cv2.matchTemplate(resized, template, method)\n",
    "        \n",
    "        # For SQDIFF methods, we look for minimum, others look for maximum\n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            _, max_val, _, min_loc = cv2.minMaxLoc(result)\n",
    "            current_val = max_val\n",
    "            current_loc = min_loc\n",
    "        else:\n",
    "            _, max_val, _, max_loc = cv2.minMaxLoc(result)\n",
    "            current_val = max_val\n",
    "            current_loc = max_loc\n",
    "        \n",
    "        # Update best match\n",
    "        if current_val > best_score:\n",
    "            best_scale = scale\n",
    "            best_score = current_val\n",
    "            best_loc = current_loc\n",
    "            best_size = (template_w, template_h)\n",
    "    \n",
    "    if best_scale:\n",
    "        # Scale the bounding box back to original image coordinates\n",
    "        orig_loc = (int(best_loc[0] / best_scale), int(best_loc[1] / best_scale))\n",
    "        orig_size = (int(best_size[0] / best_scale), int(best_size[1] / best_scale))\n",
    "        return orig_loc, orig_size, best_score\n",
    "    return None, None, 0\n",
    "\n",
    "# Load images\n",
    "template = cv2.imread('Finding/3-tiger.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "large_img = cv2.imread('Finding/3-clean.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if images loaded successfully\n",
    "if template is None or large_img is None:\n",
    "    print(\"Error: Could not load images.\")\n",
    "    exit()\n",
    "\n",
    "# Create mask for white background\n",
    "_, mask = cv2.threshold(template, 250, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# All available template matching methods\n",
    "methods = {\n",
    "    'TM_CCOEFF': cv2.TM_CCOEFF,\n",
    "    'TM_CCOEFF_NORMED': cv2.TM_CCOEFF_NORMED,\n",
    "    'TM_CCORR': cv2.TM_CCORR,\n",
    "    'TM_CCORR_NORMED': cv2.TM_CCORR_NORMED,\n",
    "    'TM_SQDIFF': cv2.TM_SQDIFF,\n",
    "    'TM_SQDIFF_NORMED': cv2.TM_SQDIFF_NORMED\n",
    "}\n",
    "\n",
    "# Display settings\n",
    "scale_percent = 30 # Smaller display size (40% of original)\n",
    "wait_time = 2000    # 2 seconds between methods (press any key to continue faster)\n",
    "\n",
    "for name, method in methods.items():\n",
    "    # Apply multi-scale template matching\n",
    "    location, size, confidence = multi_scale_template_matching(\n",
    "        large_img, template, mask, method,\n",
    "        scale_range=(0.7, 1.4), steps=20\n",
    "    )\n",
    "    \n",
    "    if location is None:\n",
    "        print(f\"{name}: No match found\")\n",
    "        continue\n",
    "    \n",
    "    # Draw rectangle on copy of original image\n",
    "    display_img = cv2.cvtColor(large_img, cv2.COLOR_GRAY2BGR)\n",
    "    top_left = (int(location[0]), int(location[1]))\n",
    "    bottom_right = (int(location[0] + size[0]), int(location[1] + size[1]))\n",
    "    cv2.rectangle(display_img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "    \n",
    "    # Resize for smaller display\n",
    "    width = int(display_img.shape[1] * scale_percent / 100)\n",
    "    height = int(display_img.shape[0] * scale_percent / 100)\n",
    "    resized_img = cv2.resize(display_img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Add method info\n",
    "    text1 = f\"Method: {name}\"\n",
    "    text2 = f\"Confidence: {confidence:.4f}\"\n",
    "    text3 = f\"Scale: {size[0]/template.shape[1]:.2f}x\"\n",
    "    cv2.putText(resized_img, text1, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    cv2.putText(resized_img, text2, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    cv2.putText(resized_img, text3, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    \n",
    "    # Display result\n",
    "    cv2.imshow('Multi-Scale Template Matching', resized_img)\n",
    "    \n",
    "    # Wait for key press or timeout\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant (Background) Color (RGB): (np.uint8(254), np.uint8(254), np.uint8(254))\n",
      "Background Color (RGB): (np.uint8(255), np.uint8(255), np.uint8(255))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Load the image (object with background)\n",
    "img = cv2.imread(\"Finding/1-cone.jpg\")  # BGR format\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for better interpretation\n",
    "\n",
    "# Flatten the image to a list of pixels\n",
    "pixels = img_rgb.reshape(-1, 3)\n",
    "\n",
    "# Find the most common color (background)\n",
    "bg_color = Counter(map(tuple, pixels)).most_common(1)[0][0]\n",
    "print(f\"Dominant (Background) Color (RGB): {bg_color}\")\n",
    "# Get corner pixels (top-left, top-right, bottom-left, bottom-right)\n",
    "corners = [\n",
    "    img_rgb[0, 0], img_rgb[0, -1],  # Top-left, Top-right\n",
    "    img_rgb[-1, 0], img_rgb[-1, -1]   # Bottom-left, Bottom-right\n",
    "]\n",
    "\n",
    "# Find the most common corner color (background)\n",
    "bg_color = Counter(map(tuple, corners)).most_common(1)[0][0]\n",
    "print(f\"Background Color (RGB): {bg_color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def simple_template_matching(image_path, template_path, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Perform basic template matching without multi-scale handling.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        template_path (str): Path to the template image.\n",
    "        threshold (float): Confidence threshold (0-1) for matches.\n",
    "    \n",
    "    Returns:\n",
    "        None (displays results in a window).\n",
    "    \"\"\"\n",
    "    # Read images\n",
    "    img = cv2.imread(image_path)\n",
    "    template = cv2.imread(template_path)\n",
    "    \n",
    "    if img is None or template is None:\n",
    "        print(\"Error: Could not load images!\")\n",
    "        return\n",
    "    \n",
    "    # Get template dimensions\n",
    "    h, w = template.shape[:2]\n",
    "    \n",
    "    # Convert to grayscale (optional but often improves performance)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(img_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    # Find locations where matches exceed the threshold\n",
    "    loc = np.where(result >= threshold)\n",
    "    \n",
    "    # Draw rectangles around matches\n",
    "    for pt in zip(*loc[::-1]):  # Switch columns and rows (x, y)\n",
    "        cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display results\n",
    "    cv2.imshow('Matches', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "simple_template_matching(\"input_image.jpg\", \"template.jpg\", threshold=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
